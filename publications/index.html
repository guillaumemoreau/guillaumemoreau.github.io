<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Guillaume Moreau | Publications</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  

  <link rel="shortcut icon" href="https://guillaumemoreau.github.io/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://guillaumemoreau.github.io/assets/css/main.css">
  <link rel="canonical" href="https://guillaumemoreau.github.io/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        Guillaume <strong>Moreau</strong>
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"></path>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"></path>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://guillaumemoreau.github.io/">about</a>

        <!-- Blog -->
        <a class="page-link" href="https://guillaumemoreau.github.io/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
        
          
        
          
        
          
            <a class="page-link" href="https://guillaumemoreau.github.io/cv/">CV (fr)</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
            <a class="page-link" href="https://guillaumemoreau.github.io/publications/">Publications</a>
          
        
          
        
          
        
          
            <a class="page-link" href="https://guillaumemoreau.github.io/teaching/">Teaching</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://guillaumemoreau.github.io/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content Publications clearfix">
    <h3 id="recent-publications">Recent publications</h3>

<h3 class="year">2023</h3>
<ol class="bibliography">
<li>

<div id="guy23">
  
    <span class="title">The Sense of Embodiment in Virtual Reality and its Assessment Methods</span>
    <span class="author">
      
        
          
            
              
                Guy, Martin,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Jeunet-Kelway, Camille,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Frontiers in Virtual Reality</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.3389/frvir.2023.1141683" target="_blank">doi</a>]
    
  
    [<a href="https://www.frontiersin.org/articles/10.3389/frvir.2023.1141683/full" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The sense of embodiment refers to the sensations with being inside, having and controlling a body. In virtual reality, it is possible to substitute a person’s body with a virtual one, referred to as an avatar. Modulations of the sense of embodiment through modifications of this avatar have perceptual and behavioural consequences on users that can influence the way users interact with the virtual environment. Therefore, it is essential to define metrics that enable a reliable assessment of the sense of embodiment in virtual reality to better understand its dimensions, the way they interact, and the influence that they have on the quality of interaction in the virtual environment. In this review, we first introduce the current knowledge on the sense of embodiment, its dimensions (senses of agency, body ownership, and self-location), and how they relate the ones with the others. Then, we dive into the different methods currently used to assess the sense of embodiment, ranging from questionnaires to neurophysiological measures. We provide a critical analysis of the existing metrics, discussing their advantages and drawbacks in the context of virtual reality. Notably, we argue that real-time measures of embodiment, that are also specific and do not require double-tasking are the most relevant in the context of virtual reality. Electroencephalography seems a good candidate for the future if its drawbacks (such as its sensitivity to movement and practicality) are improved. While the perfect metric has yet to be identified if it exists, this work provides clues on which metric to choose depending on the context, which should hopefully contribute to better assessing and understanding the sense of embodiment in virtual reality. </p>
  </span>
  
</div>
</li>
<li>
  
    <abbr>[TVCG]</abbr>
  


<div id="fourrier23">
  
    <span class="title">Handwriting for efficient text entry in industrial VR applications: influence of board orientation and sensory feedback on performance</span>
    <span class="author">
      
        
          
            
              
                Fourrier, Nicolas,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                Benaouicha, Mustapha,
              
            
          
        
      
        
          
            
              
                and <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Visualization and Computer Graphics</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1109/TVCG.2023.3320215" target="_blank">doi</a>]
    
  
    [<a href="https://hal.science/hal-04304498v1/file/TVCG___VR_handwriting___Revision%20%281%29.pdf" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Text entry in Virtual Reality (VR) is becoming an increasingly important task as the availability of hardware increases and the range of VR applications widens. This is especially true for VR industrial applications where users need to input data frequently. Large-scale industrial adoption of VR is still hampered by the productivity gap between entering data via a physical keyboard and VR data entry methods. Data entry needs to be efficient, easy-to-use and to learn and not frustrating. In this paper, we present a new data entry method based on handwriting recognition (HWR). Users can input text by simply writing on a virtual surface. We conduct a user study to determine the best writing conditions when it comes to surface orientation and sensory feedback. This feedback consists of visual, haptic, and auditory cues. We find that using a slanted board with sensory feedback is best to maximize writing speeds and minimize physical demand. We also evaluate the performance of our method in terms of text entry speed, error rate, usability and workload. The results show that handwriting in VR has high entry speed, usability with little training compared to other controller-based virtual text entry techniques. The system could be further improved by reducing high error rates through the use of more efficient handwriting recognition tools. In fact, the total error rate is 9.28% in the best condition. After 40 phrases of training, participants reach an average of 14.5 WPM, while a group with high VR familiarity reach 16.16 WPM after the same training. The highest observed textual data entry speed is 21.11 WPM.</p>
  </span>
  
</div>
</li>
<li>

<div id="VERHULST202340">
  
    <span class="title">Deep weathering effects</span>
    <span class="author">
      
        
          
            
              
                Verhulst, Adrien,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Patow, Gustavo
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Computers &amp; Graphics</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/https://doi.org/10.1016/j.cag.2023.03.006" target="_blank">doi</a>]
    
  
    [<a href="https://www.sciencedirect.com/science/article/pii/S0097849323000353" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Weathering phenomena are ubiquitous in urban environments, where it is easy to observe severely degraded old buildings as a result of water penetration. Despite being an important part of any realistic city, this kind of phenomenon has received little attention from the Computer Graphics community compared to stains resulting from biological or flow effects on the building exteriors. In this paper, we present physically-inspired deep weathering effects, where the penetration of humidity (i.e., water particles) and its interaction with a building’s internal structural elements result in large, visible degradation effects. Our implementation is based on a particle-based propagation model for humidity propagation, coupled with a spring-based interaction simulation that allows chemical interactions, like the formation of rust, to deform and destroy a building’s inner structure. To illustrate our methodology, we show a collection of deep degradation effects applied to urban models involving the creation of rust or of ice within walls.</p>
  </span>
  
</div>
</li>
</ol>

<h3 class="year">2022</h3>
<ol class="bibliography">
<li>

<div id="guy22">
  
    <span class="title">Manipulating the Sense of Embodiment in Virtual Reality: a study of the interactions between the senses of agency, self-location and ownership</span>
    <span class="author">
      
        
          
            
              
                Guy, Martin,
              
            
          
        
      
        
          
            
              
                Jeunet-Kelway, Camille,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ICAT-EGVE2022, the joint international conference of the 32nd International Conference on Artificial Reality and Telexistence &amp; the 27th Eurographics Symposium on Virtual Environments</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-03853981/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p> In Virtual Reality (VR), the Sense of Embodiment (SoE) corresponds to the feeling of controlling and owning a virtual body, usually referred to as an avatar. The SoE is generally divided into three components: the Sense of Agency (SoA) which characterises the level of control of the user over the avatar, the Sense of Self-Location (SoSL) which is the feeling to be located in the avatar and the Sense of Body-Ownership (SoBO) that represents the attribution of the virtual body to the user. While previous studies showed that the SoE can be manipulated by disturbing either the SoA, the SoBO or the SoSL, the relationships and interactions between these three components still remain unclear. In this paper, we aim at extending the understanding of the SoE and the interactions between its components by 1) experimentally manipulating them in VR via a biased visual feedback, and 2) understanding if each sub-component can be selectively altered or not. To do so, we designed a within-subject experiment where 47 right-handed participants had to perform movements of their right-hand under different experimental conditions impacting the sub-components of embodiment: the SoA was modified by impacting the control of the avatar with visual biased feedback, the SoBO was altered by modifying the realism of the virtual right hand (anthropomorphic cartoon hand or non-anthropomorphic stick “fingers”) and the SoSL was controlled via the user’s point of view (first or third person). After each trial, participants rated their level of agency, ownership and self-location on a 7-item Likert scale. Results’ analysis revealed that the three components could not be selectively altered in this experiment. Nevertheless, these preliminary results pave the way to further studies.</p>
  </span>
  
</div>
</li>
<li>

<div id="perrier22">
  
    <span class="title">Apport de la réalité augmentée comme aide technologique pour le maintien de l’autonomie de personnes présentant une maladie neurologique : revue narrative de la littérature</span>
    <span class="author">
      
        
          
            
              
                Perrier, Manon,
              
            
          
        
      
        
          
            
              
                Pillette, Léa,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Anatole.Lecuyer/" target="_blank">Lécuyer, Anatole</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Mélanie, Cogné
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Ergothérapies</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://revue.anfe.fr/2022/07/19/apport-de-la-realite-augmentee-comme-aide-technologique-pour-le-maintien-de-lautonomie-de-personnes-presentant-une-maladie-neurologique-revue-narrative-de-la-litterature/" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Introduction. Cognitive disorders can limit participation of people with neurological diseases in daily life activities, and more specifically when navigating in their outdoor environment. Augmented Reality (AR) tools seem promising for compensating these difficulties.
Aim. Our main objective was to detail and discuss the existing application fields of AR devices for people with neurological disorders.
Methods. We conducted our literature review between August and September 2021 using 2 databases: Medline and Scopus, with the following keywords: “augmented reality” AND: “neurological” (and synonyms: “neurology”, “neurologic”), “disorientation”, “mild cognitive”, “aid”, “cognition”.
Results. We selected and analysed 13 studies. The selected articles show a good acceptance of AR devices by the participants. Research focused on navigation tasks showed that most of the participants were able to complete the navigation task without any other assistance. The notion of cognitive load
which influences the user’s safety during the navigation task when using augmented reality, was often taken into account.
Conclusion. We defined a framework for the use of AR that can be applied in rehabilitation and to consider its future use in the person’s environment as a technological aid for spatial navigation. Further studies on the cognitive load in people with neurological pathology are necessary to compare the results obtained to ones on healthy participants.</p>
  </span>
  
</div>
</li>
<li>

<div id="giraldo22">
  
    <span class="title">Towards a sensitive urban wind representation in virtual reality</span>
    <span class="author">
      
        
          
            
              
                Giraldo, Gabriel,
              
            
          
        
      
        
          
            
              
                Servières, Myriam,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ISPRS International Journal of Geo-Information</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.3390/ijgi11040239" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-03633359/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Wind can influence people’s behavior and their way of inhabiting an architectural or urban space. Furthermore, virtual reality (VR) enables the simulation of different physical and sensitive phenomena such as the wind. We aim to analyze the effects of different wind representations in terms of perception of its properties and sense of presence in VR. We carry out two within-subject studies aiming at evaluating different wind representation suggestions (including audiovisual and tactile stimuli) to identify their effects on wind properties’ perception and sense of presence in the VR scene. Our analysis showed significant effects of tactile restitution over the visual effects used in the study, both for understanding wind properties and for increasing the sense of presence in the VR scene. The tactile condition (T) reduced the estimation error of wind direction by 27% compared to the visual condition (V). The wind force error was reduced by 9.8% using (T) with (V). (T) increased the sense of presence by 12.2% compared to (V). Our second experiment showed an overestimation of the wind force perceived compared to the reference value of the Beaufort scale. For the maximum force value evaluated, the average result was 91% higher than the reference value, while for the lower, the average answer was 77% higher than the reference value. Previous studies have evaluated wind rendering in virtual reality, and others have studied the visualization of wind simulation results. To our knowledge, our study is the first to compare the perception of these two types of representations as well as the effects of wind on elements of the context. We also compared the wind perception to a reference-based method, the Beaufort scale.</p>
  </span>
  
</div>
</li>
<li>

<div id="key">
  
    <span class="title">Virtual Data Sphere: Inverse Stereographic Projection for Immersive Multi-Perspective Geovisualization</span>
    <span class="author">
      
        
          
            
              
                Spur, Maxim,
              
            
          
        
      
        
          
            
              
                Tourre, Vincent,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Le Callet, Patrick
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-03735799/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Immersive geospatial visualization finds increasing application for navigation, exploration, and analysis. Many such require the display of data at different scales, often in views with three-dimensional geometry. Multi-view solutions, such as focus+context, overview+detail, and distorted projections can show different scales at the same time, and help place an area of interest within its surroundings. By inverting the principle of stereographic projection – projecting spatial features from a map onto a virtual sphere which surrounds the viewer – we present a novel technique for immersive geospatial focus+context that aims to mitigate problems with existing solutions. This sphere can intersect the map, dividing it into two parts: the inside of the sphere, which stays unchanged, and the outside, which gets projected to the surface, resulting in an inversion of the lens metaphor by distorting the context instead of the focus. This detail-in-context visualization maximizes the amount of context that can be legibly shown by the smooth compression inherent to the stereographic projection, and by utilizing otherwise unused screen space in the sky. The projection method allows for easy control over the projection and distortion characteristics by varying only two main parameters – the sphere’s radius and its position. The omnidirectional nature of our system makes it particularly well-suited for immersive displays by accommodating typical immersive exploration and fully utilizing the additional visual space available. Applying our system to an urban environment, we were able to solicit positive reactions during feedback sessions with experts from urbanism.</p>
  </span>
  
</div>
</li>
<li>
  
    <abbr>[TVCG]</abbr>
  


<div id="9676472">
  
    <span class="title">A Systematic Review of Navigation Assistance Systems for People with Dementia</span>
    <span class="author">
      
        
          
            
              
                Pillette, Léa,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Perrier, Manon,
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Anatole.Lecuyer/" target="_blank">Lécuyer, Anatole</a>,
              
            
          
        
      
        
          
            
              
                and Cogné, Melanie
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Visualization and Computer Graphics</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1109/TVCG.2022.3141383" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-03605535/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Technological developments provide solutions to alleviate the tremendous impact on the health and autonomy due to the impact of dementia on navigation abilities. We systematically reviewed the literature on devices tested to provide assistance to people with dementia during indoor, outdoor and virtual navigation (PROSPERO ID number: 215585). Medline and Scopus databases were searched from inception. Our aim was to summarize the results from the literature to guide future developments. Twenty-three articles were included in our study. Three types of information were extracted from these studies. First, the types of navigation advice the devices provided were assessed through: (i) the sensorial modality of presentation, e.g., visual and tactile stimuli, (ii) the navigation content, e.g., landmarks, and (iii) the timing of presentation, e.g., systematically at intersections. Second, we analyzed the technology that the devices were based on, e.g., smartphone. Third, the experimental methodology used to assess the devices and the navigation outcome was evaluated. We report and discuss the results from the literature based on these three main characteristics. Finally, based on these considerations, recommendations are drawn, challenges are identified and potential solutions are suggested. Augmented reality-based devices, intelligent tutoring systems and social support should particularly further be explored.</p>
  </span>
  
</div>
</li>
</ol>

<h3 class="year">2021</h3>
<ol class="bibliography">
<li>

<div id="jimaging7080141">
  
    <span class="title">Direct and Indirect vSLAM Fusion for Augmented Reality</span>
    <span class="author">
      
        
          
            
              
                Outahar, Mohamed,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Imaging</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.3390/jimaging7080141" target="_blank">doi</a>]
    
  
    [<a href="https://www.mdpi.com/2313-433X/7/8/141" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Augmented reality (AR) is an emerging technology that is applied in many fields. One of the limitations that still prevents AR to be even more widely used relates to the accessibility of devices. Indeed, the devices currently used are usually high end, expensive glasses or mobile devices. vSLAM (visual simultaneous localization and mapping) algorithms circumvent this problem by requiring relatively cheap cameras for AR. vSLAM algorithms can be classified as direct or indirect methods based on the type of data used. Each class of algorithms works optimally on a type of scene (e.g., textured or untextured) but unfortunately with little overlap. In this work, a method is proposed to fuse a direct and an indirect methods in order to have a higher robustness and to offer the possibility for AR to move seamlessly between different types of scenes. Our method is tested on three datasets against state-of-the-art direct (LSD-SLAM), semi-direct (LCSD) and indirect (ORBSLAM2) algorithms in two different scenarios: a trajectory planning and an AR scenario where a virtual object is displayed on top of the video feed; furthermore, a similar method (LCSD SLAM) is also compared to our proposal. Results show that our fusion algorithm is generally as efficient as the best algorithm both in terms of trajectory (mean errors with respect to ground truth trajectory measurements) as well as in terms of quality of the augmentation (robustness and stability). In short, we can propose a fusion algorithm that, in our tests, takes the best of both the direct and indirect methods.</p>
  </span>
  
</div>
</li>
<li>

<div id="electronics10040377">
  
    <span class="title">Detection of Removed Objects in 3D Meshes Using Up-to-Date Images for Mixed-Reality Applications</span>
    <span class="author">
      
        
          
            
              
                Roupin, Olivier,
              
            
          
        
      
        
          
            
              
                Fradet, Matthieu,
              
            
          
        
      
        
          
            
              
                Baillard, Caroline,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Electronics</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.3390/electronics10040377" target="_blank">doi</a>]
    
  
    [<a href="https://www.mdpi.com/2079-9292/10/4/377" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Precise knowledge of the real environment is a prerequisite for the integration of the real and virtual worlds in mixed-reality applications. However, real-time updating of a real environment model is a costly and difficult process; therefore, hybrid approaches have been developed: An updated world model can be inferred from an offline acquisition of the 3D world, which is then updated online using live image sequences under the condition of developing fast and robust change detection algorithms. Current algorithms are biased toward object insertion and often fail in object removal detection; in an environment where there is uniformity in the background—in color and intensity—the disappearances of foreground objects between the 3D scan of a scene and the capture of several new pictures of said scene are difficult to detect. The novelty of our approach is that we circumvent this issue by focusing on areas of least change in parts of the scene that should be occluded by the foreground. Through experimentation on realistic datasets, we show that this approach results in better detection and localization of removed objects. This technique can be paired with an insertion detection algorithm to provide a complete change detection framework.</p>
  </span>
  
</div>
</li>
</ol>

<h3 class="year">2020</h3>
<ol class="bibliography">
<li>

<div id="semaan20a">
  
    <span class="title">Camera pose estimation using collaborative databases and single building image</span>
    <span class="author">
      
        
          
            
              
                Semaan, Bernard,
              
            
          
        
      
        
          
            
              
                Servières, Myriam,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Chebaro, Bilal
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Geographic Information System</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/10.4236/jgis.2020.126036" target="_blank">doi</a>]
    
  
    [<a href="https://www.scirp.org/pdf/jgis_2020112715043978.pdf" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="spur20b">
  
    <span class="title">Exploring Multiple And Coordinated Views For Multilayered Geospatial Data In Virtual Reality</span>
    <span class="author">
      
        
          
            
              
                Spur, Maxim,
              
            
          
        
      
        
          
            
              
                Tourre, Vincent,
              
            
          
        
      
        
          
            
              
                David, Erwan,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Le Callet, Patrick
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Information</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/10.3390/info11090425" target="_blank">doi</a>]
    
  
    [<a href="https://www.mdpi.com/2078-2489/11/9/425" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>
  
    <abbr>[ISMAR]</abbr>
  


<div id="peillard20a">
  
    <span class="title">Can Retinal Projection Displays Improve Spatial Perception in Augmented Reality?</span>
    <span class="author">
      
        
          
            
              
                Peillard, Etienne,
              
            
          
        
      
        
          
            
              
                Itoh, Yuta,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=h8NkiJcAAAAJ&amp;hl=ja" target="_blank">Argelaguet, Ferran</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Anatole.Lecuyer/" target="_blank">Lécuyer, Anatole</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02911740/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>
  
    <abbr>[ISMAR]</abbr>
  


<div id="giraldo20">
  
    <span class="title">Perception of Multisensory Wind Representation in Virtual Reality</span>
    <span class="author">
      
        
          
            
              
                Giraldo, Gabriel,
              
            
          
        
      
        
          
            
              
                Servières, Myriam,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02924372/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="lombart20a">
  
    <span class="title">Effects of Physical, Non-Immersive Virtual, and Immersive Virtual Store Environments on Consumers’ Perceptions and Purchase Behavior</span>
    <span class="author">
      
        
          
            
              
                Lombart, Cindy,
              
            
          
        
      
        
          
            
              
                Millan, Elena,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Verhulst, Adrien,
              
            
          
        
      
        
          
            
              
                Labbé-Pinlon, Blandine,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Computers in Human Behavior</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1016/j.chb.2020.106374" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02551772/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The application of virtual reality in human activities has been rapidly growing during the last decade. Shopping for food is an important part of people’s daily lives. As overnight delivery services of fresh produce, such as Amazon Fresh, are in their development stage, more studies on virtual stores for perishable products are needed because the quality of FaVs cannot be easily assessed by consumers when virtual stores are used. This research examines the impact of a physical store, a non-immersive virtual store, and an immersive virtual store environment on consumers’ perceptions and purchase behavior toward fruits and vegetables (FaVs). Experimental between-subjects design (i.e., three groups), combined with a questionnaire survey (after-only design), is used to address the study objectives. The research found that consumers’ perceptions of FaVs in both non-immersive and immersive virtual stores (VS) are similar to those in a physical store. By contrast, consumers buy more FaVs in both non-immersive and immersive VS compared to a physical store. The findings also indicate that consumers tend to rely more on extrinsic cues (i.e., FaVs’ prices) in the immersive VS when evaluating the FaVs on offer and less on intrinsic cues (e.g., FaVs’ appearance) they use in the physical store. The results have important implications for practitioners and researchers with regard to the usefulness of virtual reality for better understanding of consumer behavior.
</p>
  </span>
  
</div>
</li>
<li>

<div id="spur20a">
  
    <span class="title">MapStack: Exploring Multilayered Geospatial Data in Virtual Reality</span>
    <span class="author">
      
        
          
            
              
                Spur, Maxim,
              
            
          
        
      
        
          
            
              
                Tourre, Vincent,
              
            
          
        
      
        
          
            
              
                David, Erwan,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Le Callet, Patrick
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proc. 11th International Conference on Information Visualization Theory and Applications</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02932169/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Virtual reality (VR) headsets offer a large and immersive workspace for displaying visualizations with stereoscopic vision, compared to traditional environments with monitors or printouts. The controllers for these devices further allow direct three-dimensional interaction with the virtual environment. In this paper, we make use of these advantages to implement a novel multiple and coordinated view (MCV) in the form of a vertical stack, showing tilted layers of geospatial data to facilitate an understanding of multi-layered maps. A formal study based on a use-case from urbanism that requires cross-referencing four layers of geospatial urban data augments our arguments for it by comparing it to more conventional systems similarly implemented in VR: a simpler grid of layers, and switching (blitting) layers on one map. Performance and oculometric analyses showed an advantage of the two spatial-multiplexing methods (the grid or the stack) over the temporal multiplexing in blitting. Overall, users tended to prefer the stack, be ambivalent to the grid, and show dislike for the blitting map. Perhaps more interestingly, we were also able to associate preferences in systems with user characteristics and behavior.
</p>
  </span>
  
</div>
</li>
<li>

<div id="gao19b">
  
    <span class="title">Influence of virtual objects’ shadows and lighting coherence on distance perception in optical see-through augmented reality</span>
    <span class="author">
      
        
          
            
              
                Gao, Yuan,
              
            
          
        
      
        
          
            
              
                Peillard, Etienne,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                Liu, Yue,
              
            
          
        
      
        
          
            
              
                and Wang, Yongtian
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of the Society of Information Display</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/https://doi.org/10.1002/jsid.832" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02200576/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2019</h3>
<ol class="bibliography">
<li>
  
    <abbr>[ISMAR]</abbr>
  


<div id="peillard19b">
  
    <span class="title">Studying Exocentric Distance Perception in Optical See-Through Augmented Reality</span>
    <span class="author">
      
        
          
            
              
                Peillard, Etienne,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=h8NkiJcAAAAJ&amp;hl=ja" target="_blank">Argelaguet, Ferran</a>,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Anatole.Lecuyer/" target="_blank">Lécuyer, Anatole</a>,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/10.1109/ISMAR.2019.00-13" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02200822/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>
  
    <abbr>[VR]</abbr>
  


<div id="peillard19a">
  
    <span class="title">Virtual objects look farther on the sides: the anisotropy of distance perception in virtual reality</span>
    <span class="author">
      
        
          
            
              
                Peillard, Etienne,
              
            
          
        
      
        
          
            
              
                Thébaud, Thomas,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=h8NkiJcAAAAJ&amp;hl=ja" target="_blank">Argelaguet, Ferran</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Anatole.Lecuyer/" target="_blank">Lécuyer, Anatole</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE Virtual Reality</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1109/VR.2019.8797826" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02084069/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The topic of distance perception has been widely investigated in Virtual Reality (VR). However, the vast majority of previous work mainly focused on distance perception of objects placed in front of the observer. Then, what happens when the observer looks on the side? In this paper, we study differences in distance estimation when comparing objects placed in front of the observer with objects placed on his side. Through a series of four experiments (n=85), we assessed participants’ distance estimation and ruled out potential biases. In particular, we considered the placement of visual stimuli in the field of view, users’ exploration behavior as well as the presence of depth cues. For all experiments a two-alternative forced choice (2AFC) standardized psychophysical protocol was employed, in which the main task was to determine the stimuli that seemed to be the farthest one. In summary, our results showed that the orientation of virtual stimuli with respect to the user introduces a distance perception bias: objects placed on the sides are systematically perceived farther away than objects in front. In addition, we could observe that this bias increases along with the angle, and appears to be independent of both the position of the object in the field of view as well as the quality of the virtual scene. This work sheds a new light on one of the specificities of VR environments regarding the wider subject of visual space theory. Our study paves the way for future experiments evaluating the anisotropy of distance perception in real and virtual environments.
</p>
  </span>
  
</div>
</li>
<li>

<div id="lombart19a">
  
    <span class="title">Consumer perceptions and purchase behavior toward imperfect fruits and vegetables in an immersive virtual reality grocery store</span>
    <span class="author">
      
        
          
            
              
                Lombart, Cindy,
              
            
          
        
      
        
          
            
              
                Millan, Elena,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Verhulst, Adrien,
              
            
          
        
      
        
          
            
              
                Labbé-Pinlon, Blandine,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Retailing and Consumer Services</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/10.1016/j.jretconser.2019.01.010" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01995916/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="gao19a">
  
    <span class="title">A Study on Differences in Human Perception between a Real and an AR Scene viewed in an OST-HMD</span>
    <span class="author">
      
        
          
            
              
                Gao, Yuan,
              
            
          
        
      
        
          
            
              
                Liu, Yue,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                Gao, Xue,
              
            
          
        
      
        
          
            
              
                and Wang, Yongtian
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of the Society for Information Display</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/https://doi.org/10.1002/jsid.752" target="_blank">doi</a>]
    
  
    [<a href="https://hal.inria.fr/hal-01987255/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="lombart19b">
  
    <span class="title">Comment les consommateurs réagissent-ils, en situation d’achat, face à des fruits et légumes difformes ? Premiers résultats d’une étude menée en magasin laboratoire virtuel immersif</span>
    <span class="author">
      
        
          
            
              
                Lombart, Cindy,
              
            
          
        
      
        
          
            
              
                Labbé-Pinlon, Blandine,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Verhulst, Adrien,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Revue de l’organisation Responsable</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/10.3917/ror.141.0050" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02556606/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2018</h3>
<ol class="bibliography">
<li>

<div id="julie18b">
  
    <span class="title">Ecosystème de représentations et apprentissage de la conception</span>
    <span class="author">
      
        
          
            
              
                Milovanovic, Julie,
              
            
          
        
      
        
          
            
              
                <a href="https://aau.archi.fr/equipe/siret-daniel/" target="_blank">Siret, Daniel</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Miguet, Francis
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings SCAN’18 - 8ème Séminaire de Conception Architecturale Numérique</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/10.1051/shsconf/20184701003" target="_blank">doi</a>]
    
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="milovanovic18a">
  
    <span class="title">Representational Ecosystems in Architectural Design Studio Critique: Do changes in the representational ecosystem affect tutors and students behaviors during design critiques?</span>
    <span class="author">
      
        
          
            
              
                Milovanovic, Julie,
              
            
          
        
      
        
          
            
              
                <a href="https://aau.archi.fr/equipe/siret-daniel/" target="_blank">Siret, Daniel</a>,
              
            
          
        
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and Miguet, Francis
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 36th eCAADe Conference</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="trvplus:fr:2018">
  
    <span class="title">Réalité virtuelle et réalité augmentée : mythes et réalités</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="verhulst18a">
  
    <span class="title">Influence of Being Embodied in an Obese Virtual Body on Shopping Behavior and Product Perception in VR</span>
    <span class="author">
      
        
          
            
              
                Verhulst, Adrien,
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>,
              
            
          
        
      
        
          
            
              
                Lombart, Cindy,
              
            
          
        
      
        
          
            
              
                Sugimoto, Maki,
              
            
          
        
      
        
          
            
              
                and Moreau, Guillaume
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Frontiers in Robotics and AI: Virtual Environments</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
    [<a href="https://doi.org/10.3389/frobt.2018.00113" target="_blank">doi</a>]
    
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01888990/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="moreau18a">
  
    <span class="title">Voir l’invisible : de la vision par ordinateur aux réalités augmentée et virtuelle</span>
    <span class="author">
      
        
          
            
              
                Moreau, Guillaume,
              
            
          
        
      
        
          
            
              
                and <a href="https://scholar.google.fr/citations?user=_2-Zd-MAAAAJ" target="_blank">Normand, Jean-Marie</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Revue française d’Histotechnologie</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01826891/document" target="_blank">pdf</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="trvplus:en:2018">
  
    <span class="title">Virtual Reality and Augmented Reality: myths and realities</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 id="complete-lists">Complete lists</h3>

<ul>
  <li>sorted by type: <a href="../journal/">journal papers</a>, <a href="../conferences/">conference papers</a>, <a href="../books/">books</a>, <a href="../bookchapters/">book chapters</a>
</li>
  <li><a href="../allpubyear/">sorted by year</a></li>
</ul>

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    © Copyright 2023 Guillaume Moreau.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
        Last updated: 2023/07/29.
    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://guillaumemoreau.github.io/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="https://guillaumemoreau.github.io/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://guillaumemoreau.github.io/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://guillaumemoreau.github.io/assets/css/academicons.min.css">




  </body>

</html>
